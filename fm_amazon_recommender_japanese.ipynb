{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon SageMaker の Factorization Machines と BlazingText を使用したレコメンダ システムの構築\n",
    "\n",
    "---\n",
    "\n",
    "---\n",
    "\n",
    "## 背景\n",
    "\n",
    "- Factorization Machines とは、因数分解機です。（以下、Factorization Machines）\n",
    "- レコメンダ システムは、アマゾン、並びにネットフリックス Prizeの例からもみれるように、機械学習のカタリストとなりました。\n",
    "  - ネットフリックス Prizeとは：2006年から2009年にかけて、三年間にわたって行なわれた史上最大級のアルゴリズム・コンテスト。賞金100万ドルを賭けて，186ヶ国から4万チームが参戦して争われた壮大なアルゴリズム競争です。\n",
    "- ユーザー・アイテムの Matrix Factorization　（又は、Matrix Decompositionと言い、日本語では行列の分解） は、コア・中核的な手法です。\n",
    "  - 行列の分解とは：行列と行列の積への分解。\n",
    "  - 何の為に分解するのか？行列を分解することで、計算を速く行えるようになる、という実際的なメリットがあったり、その行列の性質がわかったりするからです。\n",
    "- Factorization Machines は、linear prediction（線形予測） とペアとなったフィーチャの相互作用が因数分解された表現を組み合わせます。\n",
    "\n",
    "$$\\hat{r} = w_0 + \\sum_{i} {w_i x_i} + \\sum_{i} {\\sum_{j > i} {\\langle v_i, v_j \\rangle x_i x_j}}$$\n",
    "\n",
    "- Amazon SageMaker の built-in Factorization Machines は高度にスケーラブルです。\n",
    "\n",
    "---\n",
    "\n",
    "## セットアップ\n",
    "\n",
    "以下のセルを実行する前に：\n",
    "1. マネージメントコンソールにて、SageMaker にてノートブックインスタンスを立ち上げて下さい。\n",
    "2. 作成時に、SageMaker の IAM ポリシーをそのノートブックインスタンスに追加して、S3 の　read/write　アクセスを許可するように設定します。\n",
    "\n",
    "セル１と２は：\n",
    "3. S3 バケット、セッション等の作成。(first code cell)\n",
    "4. 必要なライブラリのインポート (second code cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "bucket = sess.default_bucket()\n",
    "base = 'DEMO-loft-recommender'\n",
    "prefix = 'sagemaker/' + base\n",
    "\n",
    "role = sagemaker.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import json\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker.predictor import json_deserializer\n",
    "from scipy.sparse import csr_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## データ\n",
    "\n",
    "[Amazon Reviews AWS Public Dataset](https://s3.amazonaws.com/amazon-reviews-pds/readme.html)\n",
    "Amazonカスタマーレビュー（商品レビュー）は、Amazonの象徴的な商品の1つです。 1995 年の最初のレビューから20 年以上の期間、何百万人ものお客様が、Amazon.com ウェブサイト上の商品に関する意見を述べ経験をシェアするために、1 億以上のレビューを投稿してきました。 これにより、Amazonカスタマーレビューは、自然言語処理（NLP）、情報検索（IR）、機械学習（ML）などの分野の学術研究者のための豊富な情報源となっています。 これに伴い、お客様の製品体験の理解に関する複数の分野におけるさらなる研究を目的として、このデータを公開しています。 具体的には、このデータセットは、顧客の評価と意見のサンプル、地理的・地域全体にわたる製品の認識の変動、およびレビューにおける販促意図またはバイアスを表すために構築されました。\n",
    "\n",
    "その内容は、\n",
    "- 1 から 5 つ星評価。\n",
    "- 2百万以上の お客様によるレビュー。\n",
    "- このノートブックでは、16万以上の デジタルビデオのレビューを使用して、機械学習を行います。 \n",
    "\n",
    "以下のセルを実行し、データセットをノートブックインスタンスの /tmp/recsys/ にダウンロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "download: s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz to ../../../../tmp/recsys/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz\n"
     ]
    }
   ],
   "source": [
    "!mkdir /tmp/recsys/\n",
    "!aws s3 cp s3://amazon-reviews-pds/tsv/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz /tmp/recsys/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas の read_csv() を使い、メモリ内の dataframe にデータセットをロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "b'Skipping line 92523: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 343254: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 524626: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 623024: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 977412: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1496867: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1711638: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 1787213: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2395306: expected 15 fields, saw 22\\n'\n",
      "b'Skipping line 2527690: expected 15 fields, saw 22\\n'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>marketplace</th>\n",
       "      <th>customer_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_parent</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_category</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>helpful_votes</th>\n",
       "      <th>total_votes</th>\n",
       "      <th>vine</th>\n",
       "      <th>verified_purchase</th>\n",
       "      <th>review_headline</th>\n",
       "      <th>review_body</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>US</td>\n",
       "      <td>12190288</td>\n",
       "      <td>R3FU16928EP5TC</td>\n",
       "      <td>B00AYB1482</td>\n",
       "      <td>668895143</td>\n",
       "      <td>Enlightened: Season 1</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>I loved it and I wish there was a season 3</td>\n",
       "      <td>I loved it and I wish there was a season 3... ...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>US</td>\n",
       "      <td>30549954</td>\n",
       "      <td>R1IZHHS1MH3AQ4</td>\n",
       "      <td>B00KQD28OM</td>\n",
       "      <td>246219280</td>\n",
       "      <td>Vicious</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>As always it seems that the best shows come fr...</td>\n",
       "      <td>As always it seems that the best shows come fr...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>US</td>\n",
       "      <td>52895410</td>\n",
       "      <td>R52R85WC6TIAH</td>\n",
       "      <td>B01489L5LQ</td>\n",
       "      <td>534732318</td>\n",
       "      <td>After Words</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>4</td>\n",
       "      <td>17</td>\n",
       "      <td>18</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Charming movie</td>\n",
       "      <td>This movie isn't perfect, but it gets a lot of...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>US</td>\n",
       "      <td>27072354</td>\n",
       "      <td>R7HOOYTVIB0DS</td>\n",
       "      <td>B008LOVIIK</td>\n",
       "      <td>239012694</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 5</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Five Stars</td>\n",
       "      <td>excellant this is what tv should be</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>US</td>\n",
       "      <td>26939022</td>\n",
       "      <td>R1XQ2N5CDOZGNX</td>\n",
       "      <td>B0094LZMT0</td>\n",
       "      <td>535858974</td>\n",
       "      <td>On The Waterfront</td>\n",
       "      <td>Digital_Video_Download</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>N</td>\n",
       "      <td>Y</td>\n",
       "      <td>Brilliant film from beginning to end</td>\n",
       "      <td>Brilliant film from beginning to end. All of t...</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  marketplace  customer_id       review_id  product_id  product_parent  \\\n",
       "0          US     12190288  R3FU16928EP5TC  B00AYB1482       668895143   \n",
       "1          US     30549954  R1IZHHS1MH3AQ4  B00KQD28OM       246219280   \n",
       "2          US     52895410   R52R85WC6TIAH  B01489L5LQ       534732318   \n",
       "3          US     27072354   R7HOOYTVIB0DS  B008LOVIIK       239012694   \n",
       "4          US     26939022  R1XQ2N5CDOZGNX  B0094LZMT0       535858974   \n",
       "\n",
       "                           product_title        product_category  star_rating  \\\n",
       "0                  Enlightened: Season 1  Digital_Video_Download            5   \n",
       "1                                Vicious  Digital_Video_Download            5   \n",
       "2                            After Words  Digital_Video_Download            4   \n",
       "3  Masterpiece: Inspector Lewis Season 5  Digital_Video_Download            5   \n",
       "4                      On The Waterfront  Digital_Video_Download            5   \n",
       "\n",
       "   helpful_votes  total_votes vine verified_purchase  \\\n",
       "0              0            0    N                 Y   \n",
       "1              0            0    N                 Y   \n",
       "2             17           18    N                 Y   \n",
       "3              0            0    N                 Y   \n",
       "4              0            0    N                 Y   \n",
       "\n",
       "                                     review_headline  \\\n",
       "0         I loved it and I wish there was a season 3   \n",
       "1  As always it seems that the best shows come fr...   \n",
       "2                                     Charming movie   \n",
       "3                                         Five Stars   \n",
       "4               Brilliant film from beginning to end   \n",
       "\n",
       "                                         review_body review_date  \n",
       "0  I loved it and I wish there was a season 3... ...  2015-08-31  \n",
       "1  As always it seems that the best shows come fr...  2015-08-31  \n",
       "2  This movie isn't perfect, but it gets a lot of...  2015-08-31  \n",
       "3                excellant this is what tv should be  2015-08-31  \n",
       "4  Brilliant film from beginning to end. All of t...  2015-08-31  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/tmp/recsys/amazon_reviews_us_Digital_Video_Download_v1_00.tsv.gz', delimiter='\\t',error_bad_lines=False)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "データセットの列は下記の通りです:\n",
    "\n",
    "- `marketplace`: 2 文字の国コード (このデータセットは、全てUS,「米国」となっています）。\n",
    "- `customer_id`: ランダムに割り当てたお客様番号又はID。 \n",
    "- `review_id`: レビューをユニークに識別できるID。\n",
    "- `product_id`: Amazon 標準識別番号 (ASIN)。  \n",
    "- `product_parent`: そのASINの親。 複数のASIN（同じ商品のカラーバリエーションまたはフォーマットのバリエーション）を１つの親にまとめることができます。\n",
    "- `product_title`: 商品のタイトル。\n",
    "- `product_category`: グループレビューに使用できる幅広い製品カテゴリ（このデータセットの場合はデジタルビデオ）\n",
    "- `star_rating`: レビューの評価 (1 から 5 つ星)。\n",
    "- `helpful_votes`: レビューが役立つと投票された数。\n",
    "- `total_votes`: レビューが受け取った投票総数。\n",
    "- `vine`: レビューは [Vine](https://www.amazon.com/gp/vine/help) のプログラムの一部として書かれているか否か。\n",
    "- `verified_purchase`: 確認済みの購入からのレビューか否か。\n",
    "- `review_headline`: レビューのタイトル。\n",
    "- `review_body`: レビューのテキスト。\n",
    "- `review_date`: レビューが書き込まれた日付。\n",
    "\n",
    "以下のセルで、トレーニングに使用するフィールド・列だけを選び、使用しない列を削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[['customer_id', 'product_id', 'product_title', 'star_rating', 'review_date']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r'reviews.csv') #メモリに存在するデータフレームをcsvに書き出し保存します。このcsvは次のハンズオンで使います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>customer_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>product_title</th>\n",
       "      <th>star_rating</th>\n",
       "      <th>review_date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>12190288</td>\n",
       "      <td>B00AYB1482</td>\n",
       "      <td>Enlightened: Season 1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30549954</td>\n",
       "      <td>B00KQD28OM</td>\n",
       "      <td>Vicious</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>52895410</td>\n",
       "      <td>B01489L5LQ</td>\n",
       "      <td>After Words</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27072354</td>\n",
       "      <td>B008LOVIIK</td>\n",
       "      <td>Masterpiece: Inspector Lewis Season 5</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26939022</td>\n",
       "      <td>B0094LZMT0</td>\n",
       "      <td>On The Waterfront</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-08-31</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   customer_id  product_id                          product_title  \\\n",
       "0     12190288  B00AYB1482                  Enlightened: Season 1   \n",
       "1     30549954  B00KQD28OM                                Vicious   \n",
       "2     52895410  B01489L5LQ                            After Words   \n",
       "3     27072354  B008LOVIIK  Masterpiece: Inspector Lewis Season 5   \n",
       "4     26939022  B0094LZMT0                      On The Waterfront   \n",
       "\n",
       "   star_rating review_date  \n",
       "0            5  2015-08-31  \n",
       "1            5  2015-08-31  \n",
       "2            4  2015-08-31  \n",
       "3            5  2015-08-31  \n",
       "4            5  2015-08-31  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のセルを実行すると、ほとんどのユーザーは、ほとんどの映画を評価しないことが分かります。 \n",
    "\n",
    "例えば、customersの統計を見てみますと、50パーセンタイルまでカウントが１、すなわちユーザは1つの評価しか投稿していないということになります。\n",
    "2万のユニークなお客様の中でおおよそ半分は投稿数が１つということです。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = df['customer_id'].value_counts() #customer_idを数え、その値を返します。\n",
    "products = df['product_id'].value_counts()   #product_idを数え、その値を返します。\n",
    "\n",
    "quantiles = [0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.1, 0.25, 0.5, 0.75, 0.9, 0.95, 0.96, 0.97, 0.98, 0.99, 1]\n",
    "print('customers count\\n', customers.size)\n",
    "print('customers\\n', customers.quantile(quantiles)) #上記のvalue_counts()で返された値を、統計してみてみます。\n",
    "print('products count \\n', products.size)\n",
    "print('products\\n', products.quantile(quantiles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のセルで映画を多く評価していないお客様と、評価を多数受けてない映画を除外します。\n",
    "\n",
    "それを、5つ以上投稿したお客様と、10つ以上のレビューを受けた映画だけをキープすることで実装します。\n",
    "\n",
    "それにより、約14万程のお客様に絞り込みました。映画の数は約3万８千となりました。（以下、customer_index と product_index をセルにて実行することにより確認できます。\n",
    "\n",
    "そして、その customerId と productId を reduced_df としてメモリにセーブします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = customers[customers >= 5]\n",
    "products = products[products >= 10]\n",
    "\n",
    "reduced_df = df.merge(pd.DataFrame({'customer_id': customers.index})).merge(pd.DataFrame({'product_id': products.index}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "お客様と映画の連番インデックス（sequential index）を作成し user と item と呼びます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customers = reduced_df['customer_id'].value_counts()\n",
    "products = reduced_df['product_id'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_index = pd.DataFrame({'customer_id': customers.index, 'user': np.arange(customers.shape[0])})\n",
    "product_index = pd.DataFrame({'product_id': products.index, \n",
    "                              'item': np.arange(products.shape[0]) + customer_index.shape[0]})\n",
    "\n",
    "reduced_df = reduced_df.merge(customer_index).merge(product_index)\n",
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最初のレビューからの日数を数え、days_since_firstを作成する（トレンドをキャプチャするfeatureとして使えます）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df['review_date'] = pd.to_datetime(reduced_df['review_date'])\n",
    "customer_first_date = reduced_df.groupby('customer_id')['review_date'].min().reset_index()\n",
    "customer_first_date.columns = ['customer_id', 'first_review_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df = reduced_df.merge(customer_first_date)\n",
    "reduced_df['days_since_first'] = (reduced_df['review_date'] - reduced_df['first_review_date']).dt.days\n",
    "reduced_df['days_since_first'] = reduced_df['days_since_first'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のセルにて、学習用のデータととテスト用のデータに分けます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = reduced_df.groupby('customer_id').last().reset_index()\n",
    "\n",
    "train_df = reduced_df.merge(test_df[['customer_id', 'product_id']], \n",
    "                            on=['customer_id', 'product_id'], \n",
    "                            how='outer', \n",
    "                            indicator=True)\n",
    "train_df = train_df[(train_df['_merge'] == 'left_only')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Factorization Machinesは、以下のデータをインプットとして受け取ります。\n",
    "  - Sparse matrix（疎行列又は、スパース行列）。ほとんど0で構成されている行列。\n",
    "  - ターゲット変数は、映画に対するそのお客様（ユーザー）の評価です。\n",
    "  - ユーザーのワンホットエンコーディング ($N$ features)　この場合、$N$は140344。\n",
    "  - 映画（アイテム）のワンホットエンコーディング ($M$ features)　$M$は38385。\n",
    "\n",
    "|Rating|User1|User2|...|UserN|Movie1|Movie2|Movie3|...|MovieM|Feature1|Feature2|...|\n",
    "|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
    "|4|1|0|...|0|1|0|0|...|0|20|2.2|...|\n",
    "|5|1|0|...|0|0|1|0|...|0|17|9.1|...|\n",
    "|3|0|1|...|0|1|0|0|...|0|3|11.0|...|\n",
    "|4|0|1|...|0|0|0|1|...|0|15|6.4|...|\n",
    "\n",
    "\n",
    "- 完全な行列をメモリに保持したくありません。従って..\n",
    "  - 疎行列を作成する。\n",
    "  - 疎行列は、CPUで効率的に動作するように設計されています。 より密度の高い行列のトレーニングの一部は、GPUで並列化することができます。\n",
    "  \n",
    "以下の function で、drameframe から、scipy の csr_matrix に変換します。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_csr_matrix(df, num_users, num_items):\n",
    "    feature_dim = num_users + num_items + 1\n",
    "    data = np.concatenate([np.array([1] * df.shape[0]),\n",
    "                           np.array([1] * df.shape[0]),\n",
    "                           df['days_since_first'].values])\n",
    "    row = np.concatenate([np.arange(df.shape[0])] * 3)\n",
    "    col = np.concatenate([df['user'].values,\n",
    "                          df['item'].values,\n",
    "                          np.array([feature_dim - 1] * df.shape[0])])\n",
    "    return csr_matrix((data, (row, col)), \n",
    "                      shape=(df.shape[0], feature_dim), \n",
    "                      dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csr = to_csr_matrix(train_df, customer_index.shape[0], product_index.shape[0])\n",
    "test_csr = to_csr_matrix(test_df, customer_index.shape[0], product_index.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下、SageMakerのfactorization machinesが必要とするスパース・レコードIOに包まれたprotobufに変換します。そして、S3バケットにアップロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_s3_protobuf(csr, label, bucket, prefix, channel='train', splits=10):\n",
    "    indices = np.array_split(np.arange(csr.shape[0]), splits)\n",
    "    for i in range(len(indices)):\n",
    "        index = indices[i]\n",
    "        buf = io.BytesIO()\n",
    "        smac.write_spmatrix_to_sparse_tensor(buf, csr[index, ], label[index])\n",
    "        buf.seek(0)\n",
    "        boto3.client('s3').upload_fileobj(buf, bucket, '{}/{}/data-{}'.format(prefix, channel, i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_s3_protobuf(train_csr, train_df['star_rating'].values.astype(np.float32), bucket, prefix)\n",
    "to_s3_protobuf(test_csr, test_df['star_rating'].values.astype(np.float32), bucket, prefix, channel='test', splits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 学習\n",
    "\n",
    "- トレーニング・ジョブを実行するための [SageMaker Python SDK](https://github.com/aws/sagemaker-python-sdk) estimatorを作成し、以下の項目を指定します。\n",
    "  - アルゴリズムが保存されているコンテナのイメージ\n",
    "  - IAM ロール\n",
    "  - ハードウェアのセットアップ\n",
    "  - アウトプットを保存する S3 のバケット\n",
    "  - アルゴリズムのハイパーパラメータ\n",
    "    - `feature_dim`: $N + M + 1$ (追加の feature は、トレントをキャプチャする `days_since_first`)\n",
    "    - `num_factors`: 因数分解された交互作用で減少させた dimension\n",
    "    - `epochs`: データセットを通過させる回数\n",
    "- `.fit()` は S3 の学習用とテスト用データを指定し、トレーニングジョブを開始します。\n",
    "- train_instance_count=4 とあるようにdistributedトレーニングの例となります。\n",
    "- この例では、cタイプのインスタンスを利用しています。\n",
    "- また、トレーニング終了後、このインスタンスは直ちに処分され、コスト軽減となります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fm = sagemaker.estimator.Estimator(\n",
    "    sagemaker.amazon.amazon_estimator.get_image_uri(boto3.Session().region_name, 'factorization-machines', 'latest'),\n",
    "    role, \n",
    "    train_instance_count=4, \n",
    "    train_instance_type='ml.c5.2xlarge',\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    base_job_name=base,\n",
    "    sagemaker_session=sess)\n",
    "\n",
    "fm.set_hyperparameters(\n",
    "    feature_dim=customer_index.shape[0] + product_index.shape[0] + 1,\n",
    "    predictor_type='regressor',\n",
    "    mini_batch_size=1000,\n",
    "    num_factors=256,\n",
    "    epochs=3)\n",
    "\n",
    "fm.fit({'train': sagemaker.s3_input('s3://{}/{}/train/'.format(bucket, prefix), distribution='ShardedByS3Key'), \n",
    "        'test': sagemaker.s3_input('s3://{}/{}/test/'.format(bucket, prefix), distribution='FullyReplicated')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ホスト・デプロイ\n",
    "\n",
    "学習を終えたモデルを、リアルタイムの本番環境へエンドポイントとしてデプロイします。\n",
    "- この際、mタイプのインスタンスを使用します。\n",
    "- initial_instance_count=1 とありますが、エンドポイント利用可能後、APIへのリクエストが増えると自動的にスケールアウトします。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fm_predictor = fm.deploy(instance_type='ml.m4.xlarge', initial_instance_count=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "API呼び出しの際に使う、メモリ内のデータをシリアル化する必要があります。predictor にてシリアライザを指定します。　"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fm_serializer(df):\n",
    "    feature_dim = customer_index.shape[0] + product_index.shape[0] + 1\n",
    "    js = {'instances': []}\n",
    "    for index, data in df.iterrows():\n",
    "        js['instances'].append({'data': {'features': {'values': [1, 1, data['days_since_first']],\n",
    "                                                      'keys': [data['user'], data['item'], feature_dim - 1],\n",
    "                                                      'shape': [feature_dim]}}})\n",
    "    return json.dumps(js)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor.content_type = 'application/json'\n",
    "fm_predictor.serializer = fm_serializer\n",
    "fm_predictor.deserializer = json_deserializer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "単一のユーザー・アイテムのリアルタイム予測は、以下の用に行います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor.predict(test_df.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "エンドポイントを削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm_predictor.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "---\n",
    "\n",
    "# Extra credit\n",
    "\n",
    "- 新しい映画を追加するとどうなるのでしょうか？\n",
    "  - データセット内に「1」と設定するフィーチャがない。\n",
    "  - 類似商品を見つけるための過去の評価がない。\n",
    "  - Factorization Machines において、コールドスタートの問題は難解です。\n",
    "- そこで、Word2vecを使用。\n",
    "  - Word embeddings を使い、自然言語処理を行う。類似の単語は同様のベクトルとなる。\n",
    "  - 連結された商品タイトルを、カスタマーレビュー履歴の文章として使用する。\n",
    "  - SageMaker の BlazingText はサブワードを扱うことができ、非常に早く実装することを可能にします。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## データ\n",
    "\n",
    "まず、商品タイトルを連結して、それぞれを 1 つの単語として扱います。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df['product_title'] = reduced_df['product_title'].apply(lambda x: x.lower().replace(' ', '-'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "そして、お客様の購入履歴の書き込みを行う。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = True\n",
    "with open('customer_purchases.txt', 'w') as f:\n",
    "    for customer, data in reduced_df.sort_values(['customer_id', 'review_date']).groupby('customer_id'):\n",
    "        if first:\n",
    "            first = False\n",
    "        else:\n",
    "            f.write('\\n')\n",
    "        f.write(' '.join(data['product_title'].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SageMakerの学習が、データを使用できるようにS3に書き込む。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = sess.upload_data('customer_purchases.txt', bucket, '{}/word2vec/train'.format(prefix))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 学習\n",
    "\n",
    "以下のセルで、SageMaker のestimatorを作成する:\n",
    "- トレーニングジョブの引数を指定する。その設定のポイントは：\n",
    "  - blazingtext のコンテナを指定。\n",
    "  - P3 インスタンスを使用。\n",
    "  - アウトプットは S3 指定したバケットに保存。\n",
    "- ハイパーパラメータを設定する。その設定のポイントは：\n",
    "  - 5 回未満登場るすタイトルを削除する。\n",
    "  - 100 dimensionalのサブスペースに埋め込む。Embed in a 100-dimensional subspace\n",
    "  - サブワードを使用してタイトルの類似性を取り込む。Use subwords to capture similarity in titles\n",
    "fit() を実行し、学習を開始する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt = sagemaker.estimator.Estimator(\n",
    "    sagemaker.amazon.amazon_estimator.get_image_uri(boto3.Session().region_name, 'blazingtext', 'latest'),\n",
    "    role, \n",
    "    train_instance_count=1, \n",
    "    train_instance_type='ml.p3.2xlarge',\n",
    "    train_volume_size = 5,\n",
    "    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
    "    sagemaker_session=sess)\n",
    "\n",
    "bt.set_hyperparameters(mode=\"skipgram\",\n",
    "    epochs=10,\n",
    "    min_count=5,\n",
    "    sampling_threshold=0.0001,\n",
    "    learning_rate=0.05,\n",
    "    window_size=5,\n",
    "    vector_dim=100,\n",
    "    negative_samples=5,\n",
    "    min_char=5,\n",
    "    max_char=10,\n",
    "    evaluation=False,\n",
    "    subwords=True)\n",
    "\n",
    "bt.fit({'train': sagemaker.s3_input(inputs, distribution='FullyReplicated', content_type='text/plain')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## モデル\n",
    "\n",
    "- S3 に保存されたモデルを抽出する。\n",
    "- そして実際、embeddingsを見てみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!aws s3 cp $bt.model_data ./"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar -xvzf model.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas の read_csv() を使い vectors.txt をメモリにロードします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors = pd.read_csv('vectors.txt', delimiter=' ', skiprows=2, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embeddings 自体の数値をみても分かりにくいことがうかがえます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.sort_values(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectors.sort_values(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "はい、１００個のタイトルを見てみましょう。 そして、t-SNEでこれをさらに減らし、上位 100タイトルをマップしてみましょう。Yes, but there's 100.  Let's reduce this further with t-SNE and map the top 100 titles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_titles = vectors[0]\n",
    "vectors = vectors.drop([0, 101], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**t-SNE**\n",
    "\n",
    "t-Distributed Stochastic Neighbor Embedding (t-SNE) is a (prize-winning) technique for dimensionality reduction that is particularly well suited for the visualization of high-dimensional datasets.\n",
    "\n",
    "It converts similarities between data points to joint probabilities and tries to minimize the Kullback-Leibler divergence between the joint probabilities of the low-dimensional embedding and the high-dimensional data. t-SNE has a cost function that is not convex, i.e. with different initializations we can get different results.\n",
    "\n",
    "t 分散確率近傍埋め込み（t-SNE）は、高次元データセットのビジュアル化に特に適した次元縮小のための技術です。\n",
    "\n",
    "データ点間の類似性を共同確率に変換し、低次元埋め込みの共同確率と高次元データの間のKullback-Leiblerの発散を最小限に抑えようとします。t-SNEは凸状ではないコスト関数を持っています。つまり、異なる初期化で 異なる結果がでます。\n",
    "\n",
    "以下で、sklearn の実装した t-SNE を使用します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "tsne = TSNE(perplexity=40, n_components=2, init='pca', n_iter=10000)\n",
    "embeddings = tsne.fit_transform(vectors.values[:100, ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pylab\n",
    "%matplotlib inline\n",
    "\n",
    "def plot(embeddings, labels):\n",
    "    pylab.figure(figsize=(20,20))\n",
    "    for i, label in enumerate(labels):\n",
    "        x, y = embeddings[i,:]\n",
    "        pylab.scatter(x, y)\n",
    "        pylab.annotate(label, xy=(x, y), xytext=(5, 2), textcoords='offset points',\n",
    "                       ha='right', va='bottom')\n",
    "    pylab.show()\n",
    "\n",
    "plot(embeddings, product_titles[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## ホスト・デプロイ\n",
    "\n",
    "モデルをリアルタイムで対応できるエンドポイントとしてデプロイします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_endpoint = bt.deploy(initial_instance_count = 1,instance_type = 'ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下のセルで、推論に使うタイトルを指定します。（一部は実際に存在するタイトルで、一部は作成されたタイトルです）。\n",
    "そのタイトルを使い、アウトプットを比較します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [\"sherlock-season-1\", \n",
    "         \"sherlock-season-2\",\n",
    "         \"sherlock-season-5\",\n",
    "         'arbitrary-sherlock-holmes-string',\n",
    "         'the-imitation-game',\n",
    "         \"abcdefghijklmn\",\n",
    "         \"keeping-up-with-the-kardashians-season-1\"]\n",
    "\n",
    "payload = {\"instances\" : words}\n",
    "\n",
    "response = bt_endpoint.predict(json.dumps(payload))\n",
    "\n",
    "vecs_df = pd.DataFrame(json.loads(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "相関と距離を計算します。Calculate correlation and distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_df = pd.DataFrame(vecs_df['vector'].values.tolist(), index=vecs_df['word'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs_df = vecs_df.transpose()\n",
    "vecs_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in vecs_df.columns:\n",
    "    print(column + ':', np.sum((vecs_df[column] - vecs_df['sherlock-season-1']) ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'sherlock-season-1'と関連しているのは:\n",
    "- 'sherlock-season-5' は実際存在しない、作られたタイトルですが、'sherlock-season-2と共に'sherlock-season-1'とよく関連しています。\n",
    "- 'arbitrary-sherlock-holmes-string' は、また作られたタイトルですが、それ程ではないですが関連はまだ強い。is also made up and relates less well but still fairly strong\n",
    "- 'the-imitation-game' はベネディクト・カンバーバッチ主演の人気のあるプライムビデオタイトルであり、中くらいの関係を持っています。任意のシャーロックのタイトルよりも関連は薄いです。is another popular Prime video title starring Benedict Cumberbatch and has a moderate relationship, but worse than the arbitrary Sherlock title\n",
    "- 'abcdefghijklmn' は作られたタイトルで、さらに関連は薄い。\n",
    "- 'keeping-up-with-the-kardashians-season-1'はさらに関係が薄いとでる。 \n",
    "\n",
    "最後に、エンドポイントを削除します。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_endpoint.delete_endpoint()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "##  ハンズオン終了時に、ノートブックインスタンスを停止して下さい! \n",
    "---\n",
    "\n",
    "# 最後に\n",
    "\n",
    "- Factorization Machinesは、大規模なデータセットに対するレコメンダ システムを迅速かつ正確に構築することを可能にします。\n",
    "- やってみること：\n",
    "  - 拡張する為に、フィーチャを追加することを試してみる。　\n",
    "  - Factorization Machines以外の他の方法と比較してみる。\n",
    "  - 2つのモデルをアンサンブルとして使ってみる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
